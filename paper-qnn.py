import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from torchvision import datasets, transforms

import pennylane as qml
from pennylane import numpy as np
import matplotlib.pyplot as plt
from tqdm.auto import tqdm
from datetime import datetime
import math
from tqdm.auto import tqdm

# -----------------------
# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# -----------------------
def load_fashion_mnist_binary():
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.2860,), (0.3530,)),  # Fashion-MNIST ì‹¤ì œ í†µê³„ê°’
        transforms.Resize((8, 8)),  # 8x8ë¡œ ì¶•ì†Œ (8 qubitsë¡œ ì¸ì½”ë”© ê°€ëŠ¥)
    ])
    
    train_set = datasets.FashionMNIST('./data', train=True, download=True, transform=transform)
    test_set = datasets.FashionMNIST('./data', train=False, download=True, transform=transform)

    def filter(dataset):
        indices = [i for i, (_, y) in enumerate(dataset) if y in [0, 6]]
        data = torch.stack([dataset[i][0] for i in indices])
        labels = torch.tensor([int(dataset[i][1] == 6) for i in indices])  # 0 â†’ 0, 6 â†’ 1
        return data, labels

    return filter(train_set), filter(test_set)

(train_x, train_y), (test_x, test_y) = load_fashion_mnist_binary()

print(f"Train data - Class 0: {(train_y == 0).sum()}, Class 1: {(train_y == 1).sum()}")
print(f"Test data - Class 0: {(test_y == 0).sum()}, Class 1: {(test_y == 1).sum()}")

# -----------------------
# FRQI ì¸ì½”ë”© êµ¬í˜„
# -----------------------
n_qubits = 8  # 8x8 ì´ë¯¸ì§€ë¥¼ ìœ„í•œ 8 qubits (6 ì¢Œí‘œ + 1 ìƒ‰ìƒ + 1 ë³´ì¡°)
n_coord_qubits = 6  # 8x8 = 64 í”½ì…€ â†’ log2(64) = 6 ì¢Œí‘œ qubits
n_color_qubits = 1  # 1 ìƒ‰ìƒ qubit
n_aux_qubits = 1    # 1 ë³´ì¡° qubit

dev = qml.device("default.qubit", wires=n_qubits)

def image_to_frqi_angles(image):
    """8x8 ì´ë¯¸ì§€ë¥¼ FRQI ê°ë„ë¡œ ë³€í™˜"""
    # ì´ë¯¸ì§€ë¥¼ í‰íƒ„í™”í•˜ê³  ì •ê·œí™”
    flat_image = image.flatten()
    # í”½ì…€ ê°’ì„ [0, Ï€/2] ë²”ìœ„ì˜ ê°ë„ë¡œ ë³€í™˜
    angles = (flat_image + 1) * math.pi / 4  # [-1,1] â†’ [0, Ï€/2]
    return angles

@qml.qnode(dev, interface="torch")
def frqi_encoding_circuit(angles, encoding_params):
    """FRQI ë°©ì‹ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ì–‘ì ìƒíƒœë¡œ ì¸ì½”ë”©"""
    # ì¢Œí‘œ qubitsë¥¼ ê· ë“± ì¤‘ì²© ìƒíƒœë¡œ ì´ˆê¸°í™”
    for i in range(n_coord_qubits):
        qml.H(wires=i)
    
    # ê° í”½ì…€ì— ëŒ€í•´ ì¡°ê±´ë¶€ íšŒì „ ì ìš© (ë³€ë¶„ ê·¼ì‚¬)
    param_idx = 0
    for pixel_idx in range(64):  # 8x8 = 64 í”½ì…€
        # í”½ì…€ ì¢Œí‘œë¥¼ ì´ì§„ìˆ˜ë¡œ ë³€í™˜
        binary_coord = format(pixel_idx, f'0{n_coord_qubits}b')
        
        # ì¡°ê±´ë¶€ íšŒì „ì„ ìœ„í•œ ë‹¤ì¤‘ ì œì–´ ê²Œì´íŠ¸ (ë³€ë¶„ ê·¼ì‚¬)
        # ì‹¤ì œ FRQIëŠ” ë§¤ìš° ë³µì¡í•˜ë¯€ë¡œ ë³€ë¶„ íšŒë¡œë¡œ ê·¼ì‚¬
        if param_idx < len(encoding_params):
            # ì¢Œí‘œ qubitsì˜ ìƒíƒœì— ë”°ë¼ ìƒ‰ìƒ qubit íšŒì „
            for coord_qubit in range(n_coord_qubits):
                if binary_coord[coord_qubit] == '1':
                    qml.CNOT(wires=[coord_qubit, n_coord_qubits])
            
            # í”½ì…€ ë°ê¸°ì— ë”°ë¥¸ íšŒì „ (ë³€ë¶„ ë§¤ê°œë³€ìˆ˜ì™€ ê²°í•©)
            angle = angles[pixel_idx] * encoding_params[param_idx % len(encoding_params)]
            qml.RY(angle, wires=n_coord_qubits)
            
            # ì œì–´ í•´ì œ
            for coord_qubit in range(n_coord_qubits):
                if binary_coord[coord_qubit] == '1':
                    qml.CNOT(wires=[coord_qubit, n_coord_qubits])
            
            param_idx += 1
    
    return qml.state()

# -----------------------
# ì–‘ì í…ì„œ íŠ¸ë ˆì¸ ë¶„ë¥˜ê¸° êµ¬í˜„
# -----------------------
n_classifier_params = 32  # ìµœëŒ€ ê¹Šì´ 32 ì œí•œ

@qml.qnode(dev, interface="torch")
def quantum_tensor_train_classifier(state_prep_params, classifier_params):
    """ì–‘ì í…ì„œ íŠ¸ë ˆì¸ ë„¤íŠ¸ì›Œí¬ ê¸°ë°˜ ë¶„ë¥˜ê¸°"""
    
    # 1. ìƒíƒœ ì¤€ë¹„ (FRQI ì¸ì½”ë”©ì˜ ë³€ë¶„ ê·¼ì‚¬)
    # ì¢Œí‘œ qubits ì´ˆê¸°í™”
    for i in range(n_coord_qubits):
        qml.H(wires=i)
    
    # ë³€ë¶„ ìƒíƒœ ì¤€ë¹„ ë ˆì´ì–´ë“¤
    layer_size = len(state_prep_params) // 4
    for layer in range(4):  # 4ê°œ ë ˆì´ì–´ë¡œ ìƒíƒœ ì¤€ë¹„
        start_idx = layer * layer_size
        end_idx = min((layer + 1) * layer_size, len(state_prep_params))
        layer_params = state_prep_params[start_idx:end_idx]
        
        # ê° qubitì— íšŒì „ ì ìš©
        for i, param in enumerate(layer_params):
            if i < n_qubits:
                qml.RY(param, wires=i)
        
        # ìˆœì°¨ì  entanglement (í…ì„œ íŠ¸ë ˆì¸ êµ¬ì¡°)
        for i in range(n_qubits - 1):
            qml.CNOT(wires=[i, i + 1])
    
    # 2. ì–‘ì í…ì„œ íŠ¸ë ˆì¸ ë¶„ë¥˜ê¸°
    # ìˆœì°¨ì  ë‘-qubit ê²Œì´íŠ¸ë“¤ (MPS êµ¬ì¡°)
    param_idx = 0
    for depth in range(min(32, len(classifier_params) // n_qubits)):  # ìµœëŒ€ ê¹Šì´ 32
        # ê° ì¸ì ‘ qubit ìŒì— ë§¤ê°œë³€ìˆ˜í™”ëœ ê²Œì´íŠ¸ ì ìš©
        for i in range(n_qubits - 1):
            if param_idx < len(classifier_params):
                # ë‘-qubit íšŒì „ ê²Œì´íŠ¸ (SU(4) ê·¼ì‚¬)
                qml.RY(classifier_params[param_idx], wires=i)
                qml.RY(classifier_params[param_idx], wires=i + 1)
                qml.CNOT(wires=[i, i + 1])
                param_idx += 1
        
        # ì›í˜• ì—°ê²° (ë§ˆì§€ë§‰ê³¼ ì²« ë²ˆì§¸ qubit)
        if param_idx < len(classifier_params):
            qml.RY(classifier_params[param_idx], wires=n_qubits - 1)
            qml.RY(classifier_params[param_idx], wires=0)
            qml.CNOT(wires=[n_qubits - 1, 0])
            param_idx += 1
    
    # 3. ì¸¡ì • (ì²« ë²ˆì§¸ qubit)
    return qml.expval(qml.PauliZ(0))

# -----------------------
# í•˜ì´ë¸Œë¦¬ë“œ ì–‘ì-ê³ ì „ ëª¨ë¸
# -----------------------
class PaperQNN(nn.Module):
    def __init__(self):
        super().__init__()
        
        # ì´ë¯¸ì§€ë‹¹ ì¸ì½”ë”© ë§¤ê°œë³€ìˆ˜ (ë³€ë¶„ FRQI ê·¼ì‚¬ìš©)
        self.encoding_params_size = 64  # ê° ì´ë¯¸ì§€ë‹¹ 64ê°œ ë§¤ê°œë³€ìˆ˜
        
        # ë¶„ë¥˜ê¸° ë§¤ê°œë³€ìˆ˜
        self.classifier_params = nn.Parameter(
            torch.randn(n_classifier_params, dtype=torch.float64) * 0.1
        )
        
        # ê° ì´ë¯¸ì§€ì˜ ì¸ì½”ë”© ë§¤ê°œë³€ìˆ˜ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
        self.encoding_params_dict = {}
        
        # ê³ ì „ í›„ì²˜ë¦¬ ë„¤íŠ¸ì›Œí¬ (ë§¤ìš° ê°„ë‹¨)
        self.classical_head = nn.Sequential(
            nn.Linear(1, 16),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(16, 1)
        ).double()
        
    def encode_image(self, image, image_id):
        """ê°œë³„ ì´ë¯¸ì§€ì— ëŒ€í•œ FRQI ì¸ì½”ë”© ë§¤ê°œë³€ìˆ˜ ìµœì í™”"""
        if image_id not in self.encoding_params_dict:
            # ìƒˆ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¸ì½”ë”© ë§¤ê°œë³€ìˆ˜ ì´ˆê¸°í™”
            encoding_params = nn.Parameter(
                torch.randn(self.encoding_params_size, dtype=torch.float64) * 0.1
            )
            
            # FRQI ëª©í‘œ ê°ë„ ê³„ì‚°
            target_angles = image_to_frqi_angles(image.squeeze())
            
            # ë³€ë¶„ ìµœì í™”ë¡œ FRQI ê·¼ì‚¬
            optimizer = optim.Adam([encoding_params], lr=0.03)
            
            for epoch in tqdm(range(10000)):  # ë…¼ë¬¸ì—ì„œëŠ” 10,000 epochì´ì§€ë§Œ ì‹œê°„ ë‹¨ì¶•
                optimizer.zero_grad()
                
                # í˜„ì¬ ìƒíƒœì™€ ëª©í‘œ FRQI ìƒíƒœ ê°„ì˜ ì¶©ì‹¤ë„ ê³„ì‚°
                # ì‹¤ì œë¡œëŠ” ë§¤ìš° ë³µì¡í•˜ë¯€ë¡œ ê°„ë‹¨í•œ ê·¼ì‚¬ ì†ì‹¤ ì‚¬ìš©
                prepared_state = frqi_encoding_circuit(target_angles, encoding_params)
                
                # ê°„ë‹¨í•œ ê·¼ì‚¬ ì†ì‹¤: ë§¤ê°œë³€ìˆ˜ê°€ ëª©í‘œ ê°ë„ì— ê°€ê¹Œì›Œì§€ë„ë¡
                loss = torch.mean((encoding_params[:len(target_angles)] - target_angles) ** 2)
                
                loss.backward()
                optimizer.step()
                
                if epoch % 10000 == 0:
                    print(f"Image {image_id} encoding epoch {epoch}, loss: {loss.item():.6f}")
            
            self.encoding_params_dict[image_id] = encoding_params.detach()
        
        return self.encoding_params_dict[image_id]
    
    def forward(self, x, image_ids=None):
        """ìˆœì „íŒŒ"""
        batch_size = x.size(0)
        results = []
        
        for i in range(batch_size):
            image = x[i]
            image_id = image_ids[i] if image_ids is not None else f"batch_{i}"
            
            # ì´ë¯¸ì§€ ì¸ì½”ë”© ë§¤ê°œë³€ìˆ˜ íšë“
            encoding_params = self.encode_image(image, image_id)
            
            # ì–‘ì ë¶„ë¥˜ê¸° ì‹¤í–‰
            quantum_output = quantum_tensor_train_classifier(
                encoding_params, self.classifier_params
            )
            
            results.append(quantum_output)
        
        # ì–‘ì ì¶œë ¥ì„ í…ì„œë¡œ ë³€í™˜
        quantum_outputs = torch.stack(results).unsqueeze(1)
        
        # ê³ ì „ í›„ì²˜ë¦¬
        final_output = self.classical_head(quantum_outputs)
        
        return final_output

# íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

# -----------------------
# í•™ìŠµ ì„¤ì •
# -----------------------
# ë°ì´í„°ë¥¼ double precisionìœ¼ë¡œ ë³€í™˜
train_x = train_x.double()
test_x = test_x.double()
train_y = train_y.double().unsqueeze(1)
test_y = test_y.double().unsqueeze(1)

# ì‘ì€ ë°°ì¹˜ í¬ê¸° (ì¸ì½”ë”© ìµœì í™” ë•Œë¬¸ì—)
train_loader = DataLoader(TensorDataset(train_x[:1000], train_y[:1000]), batch_size=4, shuffle=True)  # ìƒ˜í”Œ ì¶•ì†Œ
test_loader = DataLoader(TensorDataset(test_x[:200], test_y[:200]), batch_size=4)  # ìƒ˜í”Œ ì¶•ì†Œ

model = PaperQNN()
total_params = count_parameters(model)

print(f"\nğŸ“Š Model Analysis:")
print(f"Classifier parameters: {model.classifier_params.numel()}")
print(f"Classical head parameters: {sum(p.numel() for p in model.classical_head.parameters())}")
print(f"Total trainable parameters: {total_params:,}")
print(f"Parameter limit check: {total_params <= 50000} (â‰¤50K)")

# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
class_counts = torch.bincount(train_y[:1000].long().flatten())
class_weights = 1.0 / class_counts.float()
class_weights = class_weights / class_weights.sum() * 2

print(f"Class weights: {class_weights}")

# ìµœì í™” ì„¤ì • (ë…¼ë¬¸ ê¸°ë°˜)
optimizer = optim.Adam([
    {'params': model.classifier_params, 'lr': 0.001, 'weight_decay': 1e-5},
    {'params': model.classical_head.parameters(), 'lr': 0.001, 'weight_decay': 1e-4}
])

criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights[1]/class_weights[0])
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=10)

# -----------------------
# í›ˆë ¨ ë£¨í”„
# -----------------------
epochs = 1000  # ë…¼ë¬¸ì—ì„œëŠ” 200 epochì´ì§€ë§Œ ì‹œê°„ ë‹¨ì¶•
best_test_acc = 0
patience_counter = 0
patience = 30

train_losses, train_accs = [], []
test_losses, test_accs = [], []

print("\nğŸš€ Starting Paper-based QNN training...")

for epoch in tqdm(range(epochs)):
    model.train()
    total_loss, total_acc = 0, 0
    
    for batch_idx, (xb, yb) in enumerate(train_loader):
        optimizer.zero_grad()
        
        # ë°°ì¹˜ ë‚´ ê° ì´ë¯¸ì§€ì— ê³ ìœ  ID ë¶€ì—¬
        image_ids = [f"train_{epoch}_{batch_idx}_{i}" for i in range(xb.size(0))]
        
        preds = model(xb, image_ids)
        loss = criterion(preds, yb)
        
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        
        acc = ((torch.sigmoid(preds) > 0.5).double() == yb).double().mean()
        total_loss += loss.item()
        total_acc += acc.item()
    
    # í‰ê°€
    model.eval()
    test_loss, test_acc = 0, 0
    with torch.no_grad():
        for batch_idx, (xb, yb) in enumerate(test_loader):
            image_ids = [f"test_{epoch}_{batch_idx}_{i}" for i in range(xb.size(0))]
            preds = model(xb, image_ids)
            loss = criterion(preds, yb)
            acc = ((torch.sigmoid(preds) > 0.5).double() == yb).double().mean()
            test_loss += loss.item()
            test_acc += acc.item()
    
    avg_train_loss = total_loss / len(train_loader)
    avg_train_acc = total_acc / len(train_loader)
    avg_test_loss = test_loss / len(test_loader)
    avg_test_acc = test_acc / len(test_loader)
    
    train_losses.append(avg_train_loss)
    train_accs.append(avg_train_acc)
    test_losses.append(avg_test_loss)
    test_accs.append(avg_test_acc)
    
    scheduler.step(avg_test_acc)
    
    if avg_test_acc > best_test_acc:
        best_test_acc = avg_test_acc
        patience_counter = 0
        torch.save(model.state_dict(), 'best_paper_qnn.pth')
    else:
        patience_counter += 1
    
    if epoch % 5 == 0 or patience_counter == 0:
        print(f"[Epoch {epoch+1}] Train Acc: {avg_train_acc:.4f} | Test Acc: {avg_test_acc:.4f} | Best: {best_test_acc:.4f}")
    
    if patience_counter >= patience:
        print(f"Early stopping at epoch {epoch+1}")
        break

print(f"\nğŸ¯ Training complete! Best Test Accuracy: {best_test_acc:.4f}")

# # ê²°ê³¼ ì‹œê°í™”
# plt.figure(figsize=(12, 4))

# plt.subplot(1, 2, 1)
# plt.plot(train_losses, label='Train Loss', alpha=0.8)
# plt.plot(test_losses, label='Test Loss', alpha=0.8)
# plt.xlabel('Epoch')
# plt.ylabel('Loss')
# plt.title('Paper QNN Training - Loss')
# plt.legend()
# plt.grid(True, alpha=0.3)

# plt.subplot(1, 2, 2)
# plt.plot(train_accs, label='Train Accuracy', alpha=0.8)
# plt.plot(test_accs, label='Test Accuracy', alpha=0.8)
# plt.axhline(y=best_test_acc, color='r', linestyle='--', alpha=0.7, label=f'Best: {best_test_acc:.4f}')
# plt.xlabel('Epoch')
# plt.ylabel('Accuracy')
# plt.title('Paper QNN Training - Accuracy')
# plt.legend()
# plt.grid(True, alpha=0.3)

# plt.tight_layout()
# plt.savefig('paper_qnn_results.png', dpi=300, bbox_inches='tight')
# plt.show()

print(f"\nğŸ† Final Summary:")
print(f"Best accuracy: {best_test_acc:.4f}")
print(f"Total epochs: {len(train_accs)}")
print(f"Quantum circuit depth: â‰¤32 (as specified)")
print(f"Number of qubits: {n_qubits}")
print(f"Encoding method: FRQI (Flexible Representation of Quantum Images)")
print(f"Architecture: Quantum Tensor Train Network")